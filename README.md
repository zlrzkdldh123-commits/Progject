# H-MTL: Hierarchical Severity-Aware Multi-Task Learning for Robot Fault Diagnosis

## ğŸ“‹ Overview

This repository implements a **Hierarchical Severity-Aware Multi-Task Learning (H-MTL)** framework for progressive fault diagnosis in semiconductor transfer robot belt drives. The model jointly performs fault-type classification as the main task and severity-level estimation as the auxiliary task.

### Key Features
- ğŸ” **Fault-type Classification**: Normal â†’ Tension Reduction â†’ Wear (3 classes)
- ğŸ“Š **Severity Estimation**: Light â†’ Medium â†’ Severe (3 levels per fault type)
- ğŸ§  **SPF Module**: Severity Pattern Fusion for degradation encoding
- ğŸ”„ **IKR Module**: Iterative Knowledge Refinement (3 cycles)
- ğŸ“ˆ **EMD Loss**: Earth Mover's Distance for ordinal relationships
- ğŸ“‰ **ACR Metric**: Adjacent Confusion Rate for ordinal accuracy

## ğŸ—ï¸ Architecture

### Model Components

```
Input (Batch, 2, 780)
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   CNN Backbone      â”‚ â†’ Feature extraction (2â†’16â†’32â†’64â†’128)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   SPF Module        â”‚ â†’ Severity Pattern Fusion
â”‚  (Tension/Wear)     â”‚   â€¢ Domain-specific features
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â€¢ Severity embeddings
    â†“                     â€¢ Integrated knowledge
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   IKR Module        â”‚ â†’ Iterative Refinement (K=3)
â”‚  (3 Iterations)     â”‚   â€¢ Bidirectional knowledge transfer
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â€¢ Multi-head attention
    â†“                     â€¢ Weighted aggregation
Main Task  Sub Tasks
[Classifier] [Classifiers]
```

### Module Details

| Module | Purpose | Input | Output |
|--------|---------|-------|--------|
| **Backbone** | 1D CNN feature extraction | (B, 2, 780) | (B, 128) |
| **SPF** | Severity-aware representations | (B, 128) | (B, 128) Ã— 3 domains |
| **IKR** | Iterative knowledge exchange | (B, 128) Ã— 3 | (B, 128) Ã— 3 (refined) |
| **Classifiers** | Task predictions | (B, 128) | (B, 3) logits |

## ğŸ“¦ Installation

```bash
# Clone repository
git clone <repository-url>
cd H-MTL-FaultDiagnosis

# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt
```

### Requirements
```
torch>=2.0.0
numpy>=1.24.0
pandas>=2.0.0
scikit-learn>=1.3.0
matplotlib>=3.7.0
seaborn>=0.12.0
pyyaml>=6.0
```

## ğŸš€ Quick Start

### 1. Data Preparation

```python
from src.utils.dataset import load_industrial_data

# Load semiconductor robot vibration dataset
train_loader, test_loader = load_industrial_data(
    data_dir='data/robot_dataset',
    batch_size=64,
    seq_len=780
)
```

### 2. Model Training

```python
from src.models.h_mtl_model import H_MTL_Model
from src.train import train_model

# Initialize model
model = H_MTL_Model(seq_len=780, hidden_dim=128, num_iterations=3)

# Train
history = train_model(
    model=model,
    train_loader=train_loader,
    test_loader=test_loader,
    epochs=300,
    learning_rate=1e-3,
    device='cuda'
)
```

### 3. Evaluation

```python
from src.evaluate import evaluate_model

# Evaluate on test set
results = evaluate_model(
    model=model,
    test_loader=test_loader,
    metrics=['accuracy', 'acr', 'confusion_matrix']
)

print(f"Main Task Accuracy: {results['main_accuracy']:.4f}")
print(f"Hierarchical Accuracy: {results['hierarchical_accuracy']:.4f}")
print(f"Adjacent Confusion Rate: {results['acr']:.2f}%")
```

## ğŸ“Š Experimental Results

### Industrial Semiconductor Robot Dataset
- **Train Samples**: 7,000 cycles (1,000 per class)
- **Test Samples**: 1,400 cycles (200 per class)
- **Sampling Rate**: 25.6 kHz
- **Signal Duration**: 7.8 seconds per cycle

#### Performance Metrics

| Metric | Main Task | Hierarchical (7-class) |
|--------|-----------|------------------------|
| **Accuracy** | 100.0% | 98.90% |
| **Precision** | 100.0% | 98.87% |
| **Recall** | 100.0% | 98.99% |
| **F1-Score** | 100.0% | 98.83% |
| **ACR** | - | 1.14% |

### CWRU Bearing Dataset Benchmarking

| Model | Main Acc | Sub Acc | Macro-F1 | ACR |
|-------|----------|---------|----------|-----|
| MSCNN-LSTM | 96.9% | 96.38% | 0.9632 | 8.94% |
| CNN-Transformer | 97.13% | 96.9% | 0.9687 | 8.62% |
| ResNet18 | 97.55% | 97.45% | 0.9742 | 7.45% |
| **H-MTL (Proposed)** | **97.89%** | **97.55%** | **0.9753** | **6.49%** |

## ğŸ”§ Configuration

Edit `configs/default.yaml`:

```yaml
# Model Configuration
model:
  hidden_dim: 128
  num_iterations: 3
  input_seq_len: 780

# Training Configuration
train:
  batch_size: 64
  epochs: 300
  learning_rate: 1.0e-3
  weight_decay: 1.0e-4

# Loss Weights
loss:
  lambda_task: 1.0
  lambda_struct: 0.7
  lambda_aux: 0.3

# Data Configuration
data:
  train_split: 0.8
  seq_len: 780
  num_classes: 3
  num_severity_levels: 3
```

## ğŸ“ˆ Key Findings

### Ablation Study

| Configuration | Main Acc | 7-class Acc | F1-Score | ACR |
|---------------|----------|------------|----------|-----|
| Base (CNN-MTL) | 98.86% | 95.88% | 0.9590 | 8.71% |
| + SPF | 99.64% | 97.71% | 0.9772 | 3.00% |
| + SPF + IKR | 100.00% | 98.57% | 0.9857 | 1.43% |
| + SPF + IKR + EMD | 100.00% | 98.90% | 0.9890 | 1.14% |

### Iteration Analysis

- **Iteration 1**: Foundation knowledge transfer
- **Iteration 2**: Refined cross-task learning  
- **Iteration 3**: Final knowledge distillation
- **Optimal K**: 3 iterations (convergence achieved)

## ğŸ¯ Model Insights

### Severity Pattern Fusion (SPF)
- Encodes degradation progression from normal â†’ light â†’ medium â†’ severe
- Generates severity embeddings for tension and wear domains
- Produces continuous severity scores for auxiliary guidance

### Iterative Knowledge Refinement (IKR)
- **Step 1**: Feature exchange between tasks (linear transformation)
- **Step 2**: Multi-head attention for nonlinear dependencies
- **Step 3**: Residual update with normalization
- **Aggregation**: Softmax-weighted combination of K iterations

### Loss Design
- **Task Loss**: Standard cross-entropy for classification
- **Structural Loss**: EMD-based ordinal loss (preserves severity ordering)
- **Auxiliary Loss**: MSE for continuous severity prediction

## ğŸ“ Project Structure

```
H-MTL-FaultDiagnosis/
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ setup.py
â”‚
â”œâ”€â”€ configs/
â”‚   â”œâ”€â”€ default.yaml
â”‚   â””â”€â”€ experiment_robot.yaml
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ backbone.py          # CNN feature extractor
â”‚   â”‚   â”œâ”€â”€ spf_module.py         # Severity Pattern Fusion
â”‚   â”‚   â”œâ”€â”€ ikr_module.py         # Iterative Knowledge Refinement
â”‚   â”‚   â””â”€â”€ h_mtl_model.py        # Main model
â”‚   â”‚
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ dataset.py            # Data loading
â”‚   â”‚   â”œâ”€â”€ metrics.py            # Loss & metrics
â”‚   â”‚   â””â”€â”€ visualization.py      # Plotting utilities
â”‚   â”‚
â”‚   â”œâ”€â”€ train.py                  # Training script
â”‚   â”œâ”€â”€ evaluate.py               # Evaluation script
â”‚   â””â”€â”€ inference.py              # Inference utilities
â”‚
â”œâ”€â”€ experiments/
â”‚   â”œâ”€â”€ robot_experiment.py
â”‚   â””â”€â”€ cwru_experiment.py
â”‚
â””â”€â”€ figures/
    â”œâ”€â”€ architecture.png
    â”œâ”€â”€ results_confusion.png
    â””â”€â”€ tsne_visualization.png
```

## ğŸ”¬ Reproducibility

### Experimental Setup
- **Hardware**: GPU (NVIDIA RTX 4070 Ti Super, 16GB VRAM)
- **Framework**: PyTorch 2.0+
- **Precision**: 32-bit floating point
- **Random Seed**: 42 (for reproducibility)


